{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ::::: promid benchmark ::::: ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False # Supress tensorflow warning\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Supress tensorflow warning\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, matthews_corrcoef, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath('benchmark_promid.ipynb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tata_scan_dev_dir = dir_path + \"/../data/promoter/human_epdnew_hg38_TATA_scan_test.csv\"\n",
    "notata_scan_dev_dir = dir_path + \"/../data/promoter/human_epdnew_hg38_noTATA_scan_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tata_scan_dev = pd.read_csv(tata_scan_dev_dir, index_col=0)\n",
    "notata_scan_dev = pd.read_csv(notata_scan_dev_dir, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(seq, strand):\n",
    "    enc_mat = np.append(np.eye(4), [[0,0,0,0]], axis=0)\n",
    "    enc_mat = enc_mat.astype(np.bool)\n",
    "    mapping_pos = dict(zip(\"ACGTN\", range(5)))\n",
    "    mapping_neg = dict(zip(\"TGCAN\", range(5)))\n",
    "    \n",
    "    if(strand == \"+\"):\n",
    "        seq2 = [mapping_pos[i] for i in seq]\n",
    "    else:\n",
    "        seq = seq[::-1]\n",
    "        seq2 = [mapping_neg[i] for i in seq]\n",
    "    return enc_mat[seq2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Starting Tensorflow... loading saved model... loaded!\n",
      "\t - One-hot encoding scanned subsequences... Done!\n",
      "\t - Begin prediction\n",
      "\t\tbatch:  100 out of  423\n",
      "\t\tbatch:  200 out of  423\n",
      "\t\tbatch:  300 out of  423\n",
      "\t\tbatch:  400 out of  423\n",
      "\t Prediction finished!\n"
     ]
    }
   ],
   "source": [
    "#############  predict TATA  ##############\n",
    "# # multiprocessing\n",
    "# print(\"Number of processors: \", mp.cpu_count())\n",
    "# pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# globals\n",
    "batch_size = 128\n",
    "cutoff = 0.5\n",
    "probs_tata = []\n",
    "\n",
    "\n",
    "new_graph = tf.Graph()\n",
    "print(\"\\t - Starting Tensorflow...\", end = \" \")\n",
    "with tf.Session(graph=new_graph) as sess:\n",
    "    print(\"loading saved model...\", end = \" \")\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], \"/projects/b1017/Jerry/PromID/promid/models/model_scan\")\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"/projects/b1017/Jerry/PromID/promid/models/model_scan/variables/variables\")\n",
    "    input_x = tf.get_default_graph().get_tensor_by_name(\"input_prom:0\")\n",
    "    y = tf.get_default_graph().get_tensor_by_name(\"output_prom:0\")\n",
    "    kr = tf.get_default_graph().get_tensor_by_name(\"kr:0\")\n",
    "    in_training_mode = tf.get_default_graph().get_tensor_by_name(\"in_training_mode:0\")  \n",
    "    print(\"loaded!\")\n",
    "\n",
    "    # predict\n",
    "    print(\"\\t - One-hot encoding scanned subsequences...\", end = \" \")\n",
    "    encoded = [encode(row['seq'], row['strand']) for index, row in tata_scan_dev.iterrows()]\n",
    "    print(\"Done!\")\n",
    "#             test_res = pool.starmap(predict, [(batch, sess) for batch in chunks(encoded, batch_size)])\n",
    "    print(\"\\t - Begin prediction\")\n",
    "    i = 1\n",
    "    for batch in chunks(encoded, batch_size):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\t\\tbatch: \", i, \"out of \", math.ceil(len(encoded)/batch_size))\n",
    "        pred = sess.run(y, feed_dict={input_x: batch, kr: 1.0, in_training_mode: False})\n",
    "        probs_tata.extend([prob[0] for prob in pred])\n",
    "        i += 1\n",
    "    print(\"\\t Prediction finished!\")\n",
    "                \n",
    "\n",
    "# binary prediction\n",
    "tata_scan_dev['pred'] = [1 if prob > cutoff else 0 for prob in probs_tata]\n",
    "\n",
    "# pool.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## metrics\n",
    "# TP = len(tata_scan_dev[(tata_scan_dev['label'] == 1) & (tata_scan_dev['pred'] == 1)])\n",
    "# FP = len(tata_scan_dev[(tata_scan_dev['label'] == 0) & (tata_scan_dev['pred'] == 1)])\n",
    "# FN = len(tata_scan_dev[(tata_scan_dev['label'] == 1) & (tata_scan_dev['pred'] == 0)])\n",
    "# TN = len(tata_scan_dev[(tata_scan_dev['label'] == 0) & (tata_scan_dev['pred'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = TP/(TP + FP)\n",
    "# recall = TP/(TP + FN)\n",
    "# F1 = 2*precision*recall/(precision+recall)\n",
    "# MCC = (TP*TN - FP*FN)/(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(tata_scan_dev['label'],tata_scan_dev['pred'])\n",
    "precision = precision_score(tata_scan_dev['label'],tata_scan_dev['pred'])\n",
    "recall = recall_score(tata_scan_dev['label'],tata_scan_dev['pred'])\n",
    "F1 = f1_score(tata_scan_dev['label'],tata_scan_dev['pred'])\n",
    "MCC = matthews_corrcoef(tata_scan_dev['label'],tata_scan_dev['pred'])\n",
    "AUC = roc_auc_score(tata_scan_dev['label'],probs_tata)\n",
    "AUPR = average_precision_score(tata_scan_dev['label'],probs_tata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.16945727482678985\n",
      "precision =  0.16945727482678985\n",
      "recall =  0.4070735090152566\n",
      "F1 =  0.23929881777415415\n",
      "MCC =  0.16078539284007243\n",
      "AUC =  0.7032102464498875\n",
      "AUPR =  0.1723718738002334\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy = \", precision)\n",
    "print(\"precision = \", precision)\n",
    "print(\"recall = \", recall)\n",
    "print(\"F1 = \", F1)\n",
    "print(\"MCC = \", MCC)\n",
    "print(\"AUC = \", AUC)\n",
    "print(\"AUPR = \", AUPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Starting Tensorflow... loading saved model... loaded!\n",
      "\t - One-hot encoding scanned subsequences... Done!\n",
      "\t - Begin prediction\n",
      "\t\tbatch:  100 out of  3840\n",
      "\t\tbatch:  200 out of  3840\n",
      "\t\tbatch:  300 out of  3840\n",
      "\t\tbatch:  400 out of  3840\n",
      "\t\tbatch:  500 out of  3840\n",
      "\t\tbatch:  600 out of  3840\n",
      "\t\tbatch:  700 out of  3840\n",
      "\t\tbatch:  800 out of  3840\n",
      "\t\tbatch:  900 out of  3840\n",
      "\t\tbatch:  1000 out of  3840\n",
      "\t\tbatch:  1100 out of  3840\n",
      "\t\tbatch:  1200 out of  3840\n",
      "\t\tbatch:  1300 out of  3840\n",
      "\t\tbatch:  1400 out of  3840\n",
      "\t\tbatch:  1500 out of  3840\n",
      "\t\tbatch:  1600 out of  3840\n",
      "\t\tbatch:  1700 out of  3840\n",
      "\t\tbatch:  1800 out of  3840\n",
      "\t\tbatch:  1900 out of  3840\n",
      "\t\tbatch:  2000 out of  3840\n",
      "\t\tbatch:  2100 out of  3840\n",
      "\t\tbatch:  2200 out of  3840\n",
      "\t\tbatch:  2300 out of  3840\n",
      "\t\tbatch:  2400 out of  3840\n",
      "\t\tbatch:  2500 out of  3840\n",
      "\t\tbatch:  2600 out of  3840\n",
      "\t\tbatch:  2700 out of  3840\n",
      "\t\tbatch:  2800 out of  3840\n",
      "\t\tbatch:  2900 out of  3840\n",
      "\t\tbatch:  3000 out of  3840\n",
      "\t\tbatch:  3100 out of  3840\n",
      "\t\tbatch:  3200 out of  3840\n",
      "\t\tbatch:  3300 out of  3840\n",
      "\t\tbatch:  3400 out of  3840\n",
      "\t\tbatch:  3500 out of  3840\n",
      "\t\tbatch:  3600 out of  3840\n",
      "\t\tbatch:  3700 out of  3840\n",
      "\t\tbatch:  3800 out of  3840\n",
      "\t Prediction finished!\n"
     ]
    }
   ],
   "source": [
    "#############  predict noTATA  ##############\n",
    "# # multiprocessing\n",
    "# print(\"Number of processors: \", mp.cpu_count())\n",
    "# pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# globals\n",
    "batch_size = 128\n",
    "cutoff = 0.5\n",
    "probs_notata = []\n",
    "\n",
    "\n",
    "new_graph = tf.Graph()\n",
    "print(\"\\t - Starting Tensorflow...\", end = \" \")\n",
    "with tf.Session(graph=new_graph) as sess:\n",
    "    print(\"loading saved model...\", end = \" \")\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], \"/projects/b1017/Jerry/PromID/promid/models/model_scan\")\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"/projects/b1017/Jerry/PromID/promid/models/model_scan/variables/variables\")\n",
    "    input_x = tf.get_default_graph().get_tensor_by_name(\"input_prom:0\")\n",
    "    y = tf.get_default_graph().get_tensor_by_name(\"output_prom:0\")\n",
    "    kr = tf.get_default_graph().get_tensor_by_name(\"kr:0\")\n",
    "    in_training_mode = tf.get_default_graph().get_tensor_by_name(\"in_training_mode:0\")  \n",
    "    print(\"loaded!\")\n",
    "\n",
    "    # predict\n",
    "    print(\"\\t - One-hot encoding scanned subsequences...\", end = \" \")\n",
    "    encoded = [encode(row['seq'], row['strand']) for index, row in notata_scan_dev.iterrows()]\n",
    "    print(\"Done!\")\n",
    "#             test_res = pool.starmap(predict, [(batch, sess) for batch in chunks(encoded, batch_size)])\n",
    "    print(\"\\t - Begin prediction\")\n",
    "    i = 1\n",
    "    for batch in chunks(encoded, batch_size):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\t\\tbatch: \", i, \"out of \", math.ceil(len(encoded)/batch_size))\n",
    "        pred = sess.run(y, feed_dict={input_x: batch, kr: 1.0, in_training_mode: False})\n",
    "        probs_notata.extend([prob[0] for prob in pred])\n",
    "        i += 1\n",
    "    print(\"\\t Prediction finished!\")\n",
    "                \n",
    "\n",
    "# binary prediction\n",
    "notata_scan_dev['pred'] = [1 if prob > cutoff else 0 for prob in probs_notata]\n",
    "\n",
    "# pool.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## metrics\n",
    "# TP = len(notata_scan_dev[(notata_scan_dev['label'] == 1) & (notata_scan_dev['pred'] == 1)])\n",
    "# FP = len(notata_scan_dev[(notata_scan_dev['label'] == 0) & (notata_scan_dev['pred'] == 1)])\n",
    "# FN = len(notata_scan_dev[(notata_scan_dev['label'] == 1) & (notata_scan_dev['pred'] == 0)])\n",
    "# TN = len(notata_scan_dev[(notata_scan_dev['label'] == 0) & (notata_scan_dev['pred'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = TP/(TP + FP)\n",
    "# recall = TP/(TP + FN)\n",
    "# F1 = 2*precision*recall/(precision+recall)\n",
    "# MCC = (TP*TN - FP*FN)/(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(notata_scan_dev['label'],notata_scan_dev['pred'])\n",
    "precision = precision_score(notata_scan_dev['label'],notata_scan_dev['pred'])\n",
    "recall = recall_score(notata_scan_dev['label'],notata_scan_dev['pred'])\n",
    "F1 = f1_score(notata_scan_dev['label'],notata_scan_dev['pred'])\n",
    "MCC = matthews_corrcoef(notata_scan_dev['label'],notata_scan_dev['pred'])\n",
    "AUC = roc_auc_score(notata_scan_dev['label'],probs_notata)\n",
    "AUPR = average_precision_score(notata_scan_dev['label'],probs_notata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.20050695825049702\n",
      "precision =  0.20050695825049702\n",
      "recall =  0.4479358664031445\n",
      "F1 =  0.27701519594042473\n",
      "MCC =  0.1914509030103389\n",
      "AUC =  0.7207212019816974\n",
      "AUPR =  0.2091199064919121\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy = \", precision)\n",
    "print(\"precision = \", precision)\n",
    "print(\"recall = \", recall)\n",
    "print(\"F1 = \", F1)\n",
    "print(\"MCC = \", MCC)\n",
    "print(\"AUC = \", AUC)\n",
    "print(\"AUPR = \", AUPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.1975998270145596\n",
      "precision =  0.1975998270145596\n",
      "recall =  0.4443543975525255\n",
      "F1 =  0.27355331183855214\n",
      "MCC =  0.18871574212193554\n",
      "AUC =  0.7192282194431263\n",
      "AUPR =  0.20549190327538053\n"
     ]
    }
   ],
   "source": [
    "#############  combined  ##############\n",
    "scan_dev = pd.concat([tata_scan_dev, notata_scan_dev])\n",
    "# probs_tata.extend(probs_notata)\n",
    "probs = np.asarray(probs_tata)\n",
    "\n",
    "# ## metrics\n",
    "# TP = len(scan_dev[(scan_dev['label'] == 1) & (scan_dev['pred'] == 1)])\n",
    "# FP = len(scan_dev[(scan_dev['label'] == 0) & (scan_dev['pred'] == 1)])\n",
    "# FN = len(scan_dev[(scan_dev['label'] == 1) & (scan_dev['pred'] == 0)])\n",
    "# TN = len(scan_dev[(scan_dev['label'] == 0) & (scan_dev['pred'] == 0)])\n",
    "\n",
    "# precision = TP/(TP + FP)\n",
    "# recall = TP/(TP + FN)\n",
    "# F1 = 2*precision*recall/(precision+recall)\n",
    "# MCC = (TP*TN - FP*FN)/(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**0.5)\n",
    "\n",
    "# print(\"precision = \", precision)\n",
    "# print(\"recall = \", recall)\n",
    "# print(\"F1 = \", F1)\n",
    "# print(\"MCC = \", MCC)\n",
    "acc = accuracy_score(scan_dev['label'],scan_dev['pred'])\n",
    "precision = precision_score(scan_dev['label'],scan_dev['pred'])\n",
    "recall = recall_score(scan_dev['label'],scan_dev['pred'])\n",
    "F1 = f1_score(scan_dev['label'],scan_dev['pred'])\n",
    "MCC = matthews_corrcoef(scan_dev['label'],scan_dev['pred'])\n",
    "AUC = roc_auc_score(scan_dev['label'],probs)\n",
    "AUPR = average_precision_score(scan_dev['label'],probs)\n",
    "print(\"accuracy = \", precision)\n",
    "print(\"precision = \", precision)\n",
    "print(\"recall = \", recall)\n",
    "print(\"F1 = \", F1)\n",
    "print(\"MCC = \", MCC)\n",
    "print(\"AUC = \", AUC)\n",
    "print(\"AUPR = \", AUPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545454"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probs_tata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
